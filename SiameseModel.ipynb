{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"SiameseModel1_try.ipynb","provenance":[{"file_id":"1qyzw0jE84LTELCOVC8W13a791RghF2-d","timestamp":1618293083742}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wBX5154Y8dAW","executionInfo":{"status":"ok","timestamp":1618460900960,"user_tz":360,"elapsed":2017,"user":{"displayName":"sanyam kumar","photoUrl":"","userId":"08449971519816812093"}}},"source":["import logging\n","from tensorflow.keras import models , optimizers , losses ,activations , callbacks\n","from tensorflow.keras.layers import *\n","import tensorflow.keras.backend as K\n","from PIL import Image\n","import tensorflow as tf\n","import time\n","import os\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQGtz7gv8dAf","executionInfo":{"status":"ok","timestamp":1618460900963,"user_tz":360,"elapsed":2011,"user":{"displayName":"sanyam kumar","photoUrl":"","userId":"08449971519816812093"}}},"source":["class Recognizer (object) :\n","\n","    def __init__( self ):\n","        \n","        #TensorFlow will tell all the messages that have the label INFO\n","        tf.compat.v1.logging.set_verbosity( tf.compat.v1.logging.ERROR )\n","        \n","        # defining the dimensions of the image\n","        self.__DIMEN = 128\n","        input_shape = ( (self.__DIMEN**2) * 3 , )\n","        convolution_shape = ( self.__DIMEN , self.__DIMEN , 3 )\n","        \n","        # defining the parameters for the model\n","        kernel_size_1 = ( 4 , 4 )\n","        kernel_size_2 = ( 3 , 3 )\n","        pool_size_1 = ( 3 , 3 )\n","        pool_size_2 = ( 2 , 2 )\n","        strides = 1\n","\n","        # defining the model\n","        seq_conv_model = [\n","\n","            Reshape( input_shape=input_shape , target_shape=convolution_shape),\n","            \n","            Conv2D( 32, kernel_size=kernel_size_1 , strides=strides , activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n","            Conv2D( 32, kernel_size=kernel_size_1, strides=strides, activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n","            MaxPooling2D(pool_size=pool_size_1, strides=strides ),\n","\n","            Conv2D( 64, kernel_size=kernel_size_2 , strides=strides , activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n","            Conv2D( 64, kernel_size=kernel_size_2 , strides=strides , activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n","            MaxPooling2D(pool_size=pool_size_2 , strides=strides),\n","\n","            Flatten(),\n","\n","            Dense( 64 , activation=activations.sigmoid )\n","\n","        ]\n","\n","        seq_model = tf.keras.Sequential( seq_conv_model )\n","\n","        # passing two inputs of same shape\n","        input_x1 = Input( shape=input_shape )\n","        input_x2 = Input( shape=input_shape )\n","\n","        # getting the exactly two same models\n","        output_x1 = seq_model( input_x1 )\n","        output_x2 = seq_model( input_x2 )\n","\n","        # k.abs provides element wise absolute value\n","        distance_euclid = Lambda( lambda tensors : K.abs( tensors[0] - tensors[1] ))( [output_x1 , output_x2] )\n","        outputs = Dense( 1 , activation=activations.sigmoid) ( distance_euclid )\n","        self.__model = models.Model( [ input_x1 , input_x2 ] , outputs )\n","\n","        self.__model.compile( loss=losses.binary_crossentropy , optimizer=optimizers.Adam(lr=0.0001))\n","        \n","    def fit(self, X, Y ,  hyperparameters  ):\n","        initial_time = time.time()\n","        self.__model.fit( X  , Y ,\n","                         batch_size=hyperparameters[ 'batch_size' ] ,\n","                         callbacks=hyperparameters[ 'callbacks'],\n","                         validation_data=hyperparameters[ 'val_data' ],\n","                         epochs = hyperparameters[ 'epochs' ],\n","                         )\n","        final_time = time.time()\n","        eta = ( final_time - initial_time )\n","        time_unit = 'seconds'\n","        if eta >= 60 :\n","            eta = eta / 60\n","            time_unit = 'minutes'\n","        self.__model.summary( )\n","        print( 'Elapsed time acquired for {} epoch(s) -> {} {}'.format( hyperparameters[ 'epochs' ] , eta , time_unit ) )\n","        \n","    def save_model(self, filePath):\n","        self.__model.save(filePath)\n","        \n","    def prepare_images_from_dir( self , dir_path , flatten=True ) :\n","        images = list()\n","        images_names = os.listdir( dir_path )\n","        for imageName in images_names :\n","            image = Image.open(dir_path + imageName)\n","            resize_image = image.resize((self.__DIMEN, self.__DIMEN))\n","            array = list()\n","            for x in range(self.__DIMEN):\n","                sub_array = list()\n","                for y in range(self.__DIMEN):\n","                    sub_array.append(resize_image.load()[x, y])\n","                array.append(sub_array)\n","            image_data = np.array(array)\n","            image = np.array(np.reshape(image_data,(self.__DIMEN, self.__DIMEN, 3)))\n","            images.append(image)\n","        if flatten :\n","            images = np.array(images)\n","            return images.reshape( ( images.shape[0]  , self.__DIMEN**2 * 3  ) ).astype( np.float32 )\n","        else:\n","            return np.array(images)\n","    \n","    def prepare_images_from_dir_classes( self , dir_path , flatten=True ) :\n","        images = list()\n","        images_names = os.listdir( dir_path )\n","        list_classes = list()\n","        for i in images_names:\n","          name = i.split(\"_\")[0]\n","          if name == 'Taruneesh':\n","            list_classes.append(3)\n","          elif name == 'Chetana':\n","            list_classes.append(0)\n","          elif name == 'Neha':\n","            list_classes.append(4)\n","          elif name == 'Sanyam':\n","            list_classes.append(2)\n","          else:\n","            list_classes.append(1)\n","        for imageName in images_names :\n","            image = Image.open(dir_path + imageName)\n","            resize_image = image.resize((self.__DIMEN, self.__DIMEN))\n","            array = list()\n","            for x in range(self.__DIMEN):\n","                sub_array = list()\n","                for y in range(self.__DIMEN):\n","                    sub_array.append(resize_image.load()[x, y])\n","                array.append(sub_array)\n","            image_data = np.array(array)\n","            image = np.array(np.reshape(image_data,(self.__DIMEN, self.__DIMEN, 3)))\n","            images.append(image)\n","\n","        if flatten :\n","            images = np.array(images)\n","            return images.reshape( ( images.shape[0]  , self.__DIMEN**2 * 3  ) ).astype( np.float32 ), list_classes\n","        else:\n","            return np.array(images), list_classes\n","        \n","    def evaluate(self , test_X , test_Y  ) :\n","        return self.__model.evaluate(test_X, test_Y)\n","    \n","    def predict(self, X  ):\n","        predictions = self.__model.predict( X  )\n","        return predictions\n","    \n","    def summary(self):\n","        self.__model.summary()\n","    \n","    def load_model(self , file_path ):\n","        self.__model = models.load_model(file_path, custom_objects={'leaky_relu': tf.nn.leaky_relu})"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"1j6W7A0evi-h","executionInfo":{"status":"ok","timestamp":1618460900963,"user_tz":360,"elapsed":2005,"user":{"displayName":"sanyam kumar","photoUrl":"","userId":"08449971519816812093"}}},"source":[""],"execution_count":2,"outputs":[]}]}